---
title: "Main - 0 - Preprocessing"
author: "René Michel"
date: "September 2020"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: united
---

Each analysis step will produce a markdown html documentation. Code chunks (except the specifications) will be hidden to keep the output readable. Thus, you can either knit the whole document using the "knit" button to run the whole script at once and directly see the output, or use the "play" buttons in the right upper corner of each code chunk to run the analysis step by step within RStudio.

```{r clear environment, include = FALSE}
# clear environment
rm(list = ls())
cat("\014")
```

```{r installations, include = FALSE}


# tested with 

# R 3.6.1 (you can check your r version with R.Version()$version.string)
# win10-x64
# RStudio 1.2.1335

# installs devtools if not found on machine, needed to install packages from github
if(!("devtools" %in% installed.packages()[,"Package"])) install.packages('devtools')
library('devtools')
# will install required dependencies for RAP analysis
devtools::install_github('remichel/envRAP') 
# initialize all required packages
rmTools::libraries(ggplot2, reshape2, pracma, Rmisc, circular, scales, R.matlab, dplyr, stats, lattice, car, rmTools, knitr, kableExtra) 
```

## Preprocessing Specifications

You can find all specifications for the applied preprocessing below.

```{r specifications}
subject_list        = c(1:10,12:15)
session_list        = c(1:9)
n_soas              = 20
n_perm              = 10000# number of permutations
do_setseed          = T    # set to T if you want to reproduce the findings
do_createdirs       = T    # if T, script checks for directories and creates them if necessary
do_save             = T    # T if you want to save files. might overwrite existing datafiles
do_mm               = F    # export matlab files for mixture model analysis?
do_withinval        = T    # preproc for analysis by validity (valid vs invalid)
do_acrossval        = T    # preproc for analysis across validity (merge valid and invalid) 
exclude_1st_session = T    # exclude practice session? 
```

```{r paths, include = FALSE}
study_path          = 'D:/OSF/Main/'
data_path           = paste0(study_path,'Logfiles/')
plot_path           = paste0(study_path,'Plots/')
subject_paths       = paste0(data_path,subject_list,'/')
preprocessed_path   = paste0(study_path,'Preprocessed/')
if(do_createdirs) create_dirs(preprocessed_path, plot_path) # checks for paths and creates them if missing
```

```{r load data, include = FALSE}

# create helper vars
n_sub     = length(subject_list)
n_session = length(session_list)

# create dataset list
datasets  = as.data.frame(matrix(NA,n_sub,n_session))
for(iSub in 1:n_sub){
  for(iSession in 1:n_session){
    datasets[iSub, iSession] = paste(subject_list[iSub],"_",session_list[iSession], sep= "")
  }
}

# load & merge datasets
for (iSub in 1:n_sub){
  for(iSession in 1:n_session){
    if (iSub == 1 & iSession == 1) {
      data   = read.table(paste0(subject_paths[iSub],datasets[iSub,iSession],".txt"), sep="\t",h=T) 
    }else{
      if (file.exists(paste(subject_paths[iSub],datasets[iSub,iSession],".txt",sep=""))){
        data = rbind(data, read.table(paste0(subject_paths[iSub],datasets[iSub,iSession],".txt"), sep="\t",h=T))
      }
    }
  }
}
```


```{r filter data, include = FALSE}
# Exclude invalid trials (to slow responses & broken fixations), practice trials and first practice session

# mode = 0 (practice)
# mode = 1 (quest / familiarization phase, only session 1)
# mode = 2 (test trials)

raw       = data # keep raw dataset

if(exclude_1st_session == T){
  data      = subset(data,data$mode > 1 & data$session > 1 & data$abort == "VALID")
}else{
  data      = subset(data,data$mode > 1 & data$abort == "VALID")
}
```


```{r statistics about lost fixations, echo = FALSE}
# Statistics about lost fixations

if(exclude_1st_session == T){
  abort     = subset(raw, raw$mode > 1 & raw$session > 1)
}else{
  abort     = subset(raw, raw$mode > 1)
}

# calculate n of broken fixations per subject
abort_long = abort %>% group_by(subject, abort) %>% tally()
abort_long = abort_long[abort_long$abort == "FIXLOST",]

# calculate n of trials per subject
abort_n = abort %>% group_by(subject) %>% tally()
abort_long$trials = abort_n$n

# calculate percentage of broken fixation
abort_long$perc = abort_long$n/abort_long$trials*100

knitr::kable(abort_long) %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(width = "100%")

disp(paste('Percentage of broken fixations: M =' , round(mean(abort_long$perc),2), '; SD =', round(sd(abort_long$perc),2)))
```



```{r prepare dataset, include = FALSE}

# align SOAs
# logfiles contain exact screen timing estimates from PTB, therefore they may vary slightly across sessions
# set verbose or difference_plot to T to check for deviations after rounding
data$soa = align_soas(data$soa,verbose = F, difference_plot = F)

# create / recode variables
data$target_position  = factor(data$target_position,levels = c("left","right"))
data$cue_position     = factor(data$cue_position,levels = c("left","right"))
data$validity         = as.factor(ifelse(data$cue_position == data$target_position, "valid", "invalid"))
data$rtms             = data$rt*1000

# compute error values
data$error   = as.numeric(data$target_degree)-as.numeric(data$reported_degree) # calculate raw error [-360, 360]
data$error   = ifelse(data$error > 180, 360-data$error,
                      ifelse(data$error < -180, -360-data$error, 
                             data$error)) # recode errors > 180 / <-180 to get error values in [-180, 180]
data$abserr           = abs(data$error) # recode to absolute values
data$correct_90 = ifelse(data$abserr < 90, 1, 0) # dichotomize absolute errors into hits/misses to check whether QUEST was successful
```

## Sanity Checks

The following tables serve to double-check all relevant cells, e.g. if any value is missing. 

```{r sanity checks, echo = F}

# check distribution of trials per cell
knitr::kable(xtabs(~data$subject+data$session)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  add_header_above(c("Subject", "Session" = 8)) %>%
  scroll_box(width = "100%")
knitr::kable(xtabs(~data$subject+data$soa)) %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  add_header_above(c("Subject", "SOA" = 20)) %>%
  scroll_box(width = "100%")
knitr::kable(xtabs(~data$subject+data$validity)) %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  add_header_above(c("Subject", "Validity" = 2)) %>%
  scroll_box(width = "100%")

knitr::kable(xtabs(~data$subject[data$validity == "valid"]+data$soa[data$validity == "valid"])) %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  add_header_above(c("Subject", "SOA" = 20)) %>%
  add_header_above(c("valid" = 21)) %>%
  scroll_box(width = "100%")

knitr::kable(xtabs(~data$subject[data$validity == "invalid"]+data$soa[data$validity == "invalid"])) %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  add_header_above(c("Subject", "SOA" = 20)) %>%
  add_header_above(c("invalid" = 21)) %>%
  scroll_box(width = "100%")
```

## Performance Checks

Performance per subject per session. We have preregistered that a session with an accuracy <.60 or >.80 had to be excluded, which was indeed not the case for any of the subjects or sessions.

```{r performance checks, echo = F}

# check performance per session per participant
performance = aggregate(correct_90 ~ subject+session,data,mean)

knitr::kable(xtabs(performance$correct_90 ~ performance$subject+performance$session)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  add_header_above(c("Subject", "Session" = 8))  %>% 
  add_header_above(c("", "Performance (+/- 90° = hit)" = 8))  %>%
  scroll_box(width = "100%")

if(length(which(xtabs(performance$correct_90 ~ performance$subject+performance$session) < .60 | xtabs(performance$correct_90 ~ performance$subject+performance$session) > .80)) > 0){
  warning('Some sessions exceed the performance boundaries:')
}else{
  disp('All sessions within preregistered performance boundaries!')
}
```

```{r r export, include = FALSE}
# export preprocessed data for further analyses and plotting
if(do_save)  save(raw, file   = paste0(preprocessed_path,"raw.Rdata"))
if(do_save)  save(data, file   = paste0(preprocessed_path,"preprocessed.Rdata"))
if(do_save)  save(performance, file = paste0(preprocessed_path,"performance.Rdata"))

```


```{r matlab export, include = FALSE}

# export as matlab files for mixture modelling

if(do_mm){
  
  full_data = data # store full dataset 
  

  for (iSub in subject_list){

    
    # subset to single subject
    data = full_data[full_data$subject == iSub,]
    
    # sort dataset by validity & SOA
    data = arrange(data,validity, soa)
    
    # for analysis within validity conditions
    if(do_withinval){
      
      # create empty matrix for matlab data
      memfit  = as.data.frame(matrix(NA,max(xtabs(~data$validity+data$soa)),length(unique(data$validity))*length(unique(data$soa))))
      # write error values in matrix memfit columnwise for each SOA*validity combination
      for (j in 1:length(unique(data$validity))){
        for (i in 1:length(unique(data$soa))){
          k = (j-1)*length(unique(data$soa))+i # save error values in kth column with current error vector
          # save subset of current SOA/val combination in kth column
          memfit[,k]= subset(data, data$validity == unique(data$validity)[j] &  data$soa == unique(data$soa)[i])$error 
          # name column with current SOA*validity combination
          colnames(memfit)[k] = paste0(unique(data$validity)[j],'_',unique(data$soa)[i]) 
        }
      }
      
      # save colnames in separate names variable
      names = colnames(memfit)
      
      # save to files
      if(do_save) writeMat(paste0(preprocessed_path,iSub,"_mm_data.mat"), d = memfit)
      if(do_save) save(names, file=paste0(preprocessed_path,iSub,"_mm_names.R"))
      
      # prepare permutations for MM (single subject level, shuffle SOA labels within valid/invalid)
      if (n_perm > 0){

        
        # set seed for reproducible findings
        if(do_setseed) set.seed(iSub)
        # unlist valid and invalid errors and assign to single vectors to sample from them later
        invalid     = unlist(memfit[1:n_soas])
        valid       = unlist(memfit[-c(1:n_soas)])
        # create empty list to write permutations in, each dataframe within this list will be one permutation
        perm_lists  = list()        
        # do all required permutations by sampling from invalid & valid vectors
        for (i in 1:n_perm){
          if(!mod(i,100)) print(paste('withinval',iSub, 'Perm', i))
          memfit_perm = as.data.frame(matrix(NA,max(xtabs(~data$validity+data$soa)),length(unique(data$validity))*length(unique(data$soa))))
          colnames(memfit_perm) = names
          memfit_perm[1:(n_soas)] = sample(invalid)
          memfit_perm[(n_soas+1):(2*n_soas)]= sample(valid)
          # assign permutated dataset to perm_list
          perm_lists[[paste0("perm_",i)]] = memfit_perm 
        }
        # save to file
        if(do_save) writeMat(paste0(preprocessed_path,iSub,"_mm_permlist.mat"), perms = perm_lists)
      }
    }
    
    
    # for across validity analysis
    if(do_acrossval){

      # create empty matrix for matlab data
      memfit  = as.data.frame(matrix(NA,max(xtabs(~data$soa)),length(unique(data$soa))))
      
      # write error values in matrix memfit columnwise for each SOA*validity combination
      for (i in 1:length(unique(data$soa))){
        # save subset of current SOA/val combination in kth column
        memfit[,i]= subset(data, data$soa == unique(data$soa)[i])$error 
        # name column with current SOA*validity combination
        colnames(memfit)[i] = paste0('soa_',unique(data$soa)[i]) 
      }

      # save colnames in separate names variable
      names = colnames(memfit)
      
      # save to file
      if(do_save) writeMat(paste0(preprocessed_path,iSub,"_mm_data_acrossval.mat"), d = memfit)
      if(do_save) save(names, file=paste0(preprocessed_path,iSub,"_mm_names_acrossval.R"))

      
      # prepare permutations
      if (n_perm > 0){ 
        
        # set seed for reproducible findings
        if(do_setseed) set.seed(iSub)
        # unlist valid and invalid errors and assign to single vectors to sample from them later
        alltrials     = unlist(memfit)
        # create empty list to write permutations in
        perm_lists  = list()        
        # do all required permutations by sampling from invalid & valid vectors
        for (i in 1:n_perm){
          if(!mod(i,100)) print(paste('acrossval',iSub, 'Perm', i))
          memfit_perm = as.data.frame(matrix(NA,max(xtabs(~data$soa)),length(unique(data$soa))))
          colnames(memfit_perm) = names
          memfit_perm[1:(n_soas)] = sample(alltrials)
          # assign permutated dataset to perm_list
          perm_lists[[paste0("perm_",i)]] = memfit_perm 
        }
        # save to file
        if(do_save) writeMat(paste0(preprocessed_path,iSub,"_mm_permlist_acrossval.mat"), perms = perm_lists)
        
      }
    }
  }
}
```


